{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost.py",
      "provenance": [],
      "authorship_tag": "ABX9TyN86QCQfGZDVlzUMd/IZHzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel-haddad/EnsembleClassifiersReview/blob/main/xgboost_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPTGMzES0AdC",
        "outputId": "51831e39-5e91-4c54-99dd-0ab0fccc0cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 81.87%\n",
            "Accuracy: 80.32% | Std dev: 1.56%\n",
            "+ ----------------------------- MODEL STATISTICS ----------------------------- +\n",
            "Train dist: 26.27% | Test dist: 27.17%\n",
            "--------------------------------------------------------------------------------\n",
            "Accuracy: 80.31% | Precision: 67.87% | Recall: 52.26%\n",
            "--------------------------------------------------------------------------------\n",
            "AUC ROC: 85.81% | F1: 59.06% | LL: -855.7245026208693\n",
            "+ ------------------------------------------------------------------------------ +\n",
            "[0.01190476 0.         0.00744048 0.         0.00595238 0.\n",
            " 0.00892857 0.         0.02380952 0.         0.0014881  0.00446429\n",
            " 0.01190476 0.         0.03720238 0.         0.00297619 0.02083333\n",
            " 0.         0.0014881  0.         0.         0.00297619 0.01785714\n",
            " 0.         0.         0.00297619 0.         0.         0.00595238\n",
            " 0.         0.01934524 0.0297619  0.03422619 0.03125    0.02529762\n",
            " 0.         0.02678571 0.00595238 0.04017857 0.00892857 0.01488095\n",
            " 0.15625    0.24553572 0.19345239]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Churn prediction: XGBoost Review\n",
        "> Author: Samuel Haddad SimÃµes Machado\n",
        "> Date: jun/2022\n",
        "> Licence: Open Source\n",
        "'''\n",
        "# general libs\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "# modeling libs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# preparation lib\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "\n",
        "# import the dataset and create the dataframe\n",
        "df_churn = pd.read_csv('https://raw.githubusercontent.com/samuel-haddad/TreeClassifiersReview/main/WA_Fn-UseC_-Telco-Customer-Churn.csv', delimiter=',')\n",
        "\n",
        "#copy df\n",
        "df_prep = df_churn.copy()\n",
        "\n",
        "df_prep['TotalCharges'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
        "\n",
        "df_prep['TotalCharges'] = pd.to_numeric(df_prep['TotalCharges'])\n",
        "\n",
        "#df_prep.loc[:, ['TotalCharges']].replace (r'\\s+', np.nan, regex = True, inplace = True)\n",
        "\n",
        "#imp\n",
        "imp = IterativeImputer(max_iter=10, random_state=0)\n",
        "imp.fit(df_prep[['TotalCharges']])\n",
        "\n",
        "#transform\n",
        "df_ii = imp.transform(df_prep[['TotalCharges']])\n",
        "\n",
        "#replace\n",
        "df_prep[['TotalCharges']] = df_ii\n",
        "df_churn_gold = df_prep\n",
        "\n",
        "# dummization\n",
        "df_churn_gold['Churn'].replace({'No':0, 'Yes':1}, inplace=True)\n",
        "df_dummies = pd.get_dummies(df_churn_gold.drop(['customerID','SeniorCitizen', 'tenure','MonthlyCharges', 'TotalCharges', 'Churn'], axis=1))\n",
        "df = pd.concat([df_dummies, df_churn_gold[['SeniorCitizen', 'tenure','MonthlyCharges', 'TotalCharges', 'Churn']]], axis=1)\n",
        "\n",
        "\n",
        "# extract the explanatory variables\n",
        "X, y = df.drop('Churn', axis=1), df['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# define the model & hyperparameter tunning\n",
        "clf = XGBClassifier(objective = 'binary:logistic',\n",
        "                    n_estimators = 100,\n",
        "                    learning_rate = 0.1,\n",
        "                    booster = 'gbtree',\n",
        "                    importance_type = 'weight'\n",
        "                    )\n",
        "\n",
        "# training the model\n",
        "clf.fit(X_train, y_train)\n",
        "score = clf.score(X_train, y_train)\n",
        "print('Train score: {}%'.format(round(score*100, 2)))\n",
        "\n",
        "# evaluate the model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "n_scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\n",
        "# report performance\n",
        "print('Accuracy: {}% | Std dev: {}%'.format(round(mean(n_scores)*100,2), round(std(n_scores)*100, 2)))\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# compare train & test distribuition\n",
        "y_train_dist = y_train.sum()/len(y_train)\n",
        "y_test_dist = y_test.sum()/len(y_test)\n",
        "\n",
        "# statistics\n",
        "print('+',29*'-','MODEL STATISTICS',29*'-','+')\n",
        "print('Train dist: {}%'.format(round(y_train_dist*100, 2))\n",
        "        ,'| Test dist: {}%'.format(round(y_test_dist*100, 2)))\n",
        "print(80*'-')\n",
        "print(\"Accuracy: {}%\".format((metrics.accuracy_score(y_test, y_pred)*100).round(2))\n",
        "        ,\"| Precision: {}%\".format((metrics.precision_score(y_test, y_pred)*100).round(2))\n",
        "        ,\"| Recall: {}%\".format((metrics.recall_score(y_test, y_pred)*100).round(2)))\n",
        "print(80*'-')\n",
        "print(\"AUC ROC: {}%\".format((roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])*100).round(2))\n",
        "        ,\"| F1: {}%\".format(((f1_score(y_test, y_pred))*100).round(2))\n",
        "        ,'| LL: {}'.format(-metrics.log_loss(y_test, clf.predict_proba(X_test), normalize=False)))\n",
        "print('+',78*'-','+')\n",
        "print(clf.feature_importances_) # percentual for wheight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "II4Jsu2I8vNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}